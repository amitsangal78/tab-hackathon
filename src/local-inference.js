const { pipeline } = require('@xenova/transformers');

(async () => {
  try {
    console.log("ğŸ¤– Loading model locally...");
    
    // Load the text generation pipeline
    const generator = await pipeline('text-generation', 'Xenova/gpt2');
    
    const input = "Hey There!";
    console.log(`ğŸ“ Input: "${input}"`);
    
    // Generate text
    const result = await generator(input, {
      max_new_tokens: 10,
      do_sample: true,
      temperature: 0.7
    });
    
    console.log("âœ… Generated:", result[0].generated_text);
    
  } catch (error) {
    console.error("âŒ Error occurred:", error.message);
    console.log("\nğŸ’¡ This approach runs the model locally without needing API tokens.");
  }
})(); 